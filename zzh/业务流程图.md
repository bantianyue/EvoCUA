# EvoCUA 业务数据流文档

## 1. 总体数据流概览

本文档描述从用户输入命令到系统返回结果的完整数据流转过程。

```
用户输入 (命令行参数)
        ↓
   [配置加载层]
        ↓
   [任务分发层]
        ↓
   [多进程执行层]
        ↓
   [单任务处理循环]
        ↓
   [结果返回层]
```

---

## 2. 详细数据流

### 2.1 用户输入 → 配置加载

**入口:** `run_multienv_evocua.py:528`

**用户输入数据:**
```bash
python run_multienv_evocua.py \
  --test_all_meta_path evaluation_examples/test_nogdrive.json \
  --provider_name aws \
  --model EvoCUA-S2 \
  --num_envs 30 \
  --max_steps 50 \
  --prompt_style S2
```

**数据流转:**

```
用户命令行参数
    ↓
┌─────────────────────────────────────────────────────────┐
│  argparse.parser (config 函数)                          │
│  位置: run_multienv_evocua.py:108-180                   │
├─────────────────────────────────────────────────────────┤
│  输入: sys.argv                                         │
│  输出: args (Namespace对象)                             │
│                                                         │
│  关键数据字段:                                          │
│  - args.test_all_meta_path: 任务配置文件路径            │
│  - args.provider_name: 云提供商 (aws/azure/docker)      │
│  - args.model: 模型名称 (EvoCUA-S2)                     │
│  - args.num_envs: 并行环境数 (30)                       │
│  - args.max_steps: 最大步数 (50)                        │
│  - args.prompt_style: 提示风格 (S1/S2)                  │
│  - args.observation_type: 观察类型 (screenshot)         │
│  - args.result_dir: 结果目录                            │
└───────────────────────────┬─────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────┐
│  环境变量加载 (.env)                                    │
│  位置: run_multienv_evocua.py:104-106                   │
├─────────────────────────────────────────────────────────┤
│  输入: .env 文件                                        │
│  输出: os.environ                                       │
│                                                         │
│  关键数据字段:                                          │
│  - OPENAI_API_KEY: LLM API密钥                          │
│  - OPENAI_BASE_URL: LLM服务地址                         │
│  - AWS_ACCESS_KEY_ID: AWS访问密钥                       │
│  - AWS_SECRET_ACCESS_KEY: AWS密钥                       │
│  - AWS_REGION: AWS区域                                  │
└───────────────────────────┬─────────────────────────────┘
                            ↓
                        args 对象
```

---

### 2.2 配置 → 任务分发

**位置:** `run_multienv_evocua.py:549-561`

**数据流转:**

```
args 对象
    ↓
┌─────────────────────────────────────────────────────────┐
│  任务配置加载                                            │
│  位置: run_multienv_evocua.py:549-550                   │
├─────────────────────────────────────────────────────────┤
│  输入: args.test_all_meta_path                          │
│  输出: test_all_meta (dict)                             │
│                                                         │
│  数据格式:                                              │
│  {                                                      │
│    "chrome": ["task1", "task2", ...],                   │
│    "libreoffice_calc": ["task3", ...],                  │
│    "gimp": ["task4", ...]                               │
│  }                                                      │
└───────────────────────────┬─────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────┐
│  任务过滤与准备                                          │
│  位置: run_multienv_evocua.py:552-565                   │
├─────────────────────────────────────────────────────────┤
│  输入: test_all_meta, args                              │
│  输出: test_file_list (filtered)                        │
│                                                         │
│  处理步骤:                                              │
│  1. 按域名过滤 (args.domain != "all")                   │
│  2. 排除已完成的任务 (get_unfinished)                   │
│  3. 生成待执行任务列表                                   │
└───────────────────────────┬─────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────┐
│  任务队列创建                                            │
│  位置: run_multienv_evocua.py:396-402                   │
├─────────────────────────────────────────────────────────┤
│  输入: test_file_list                                   │
│  输出: task_queue (multiprocessing.Queue)               │
│                                                         │
│  数据格式:                                              │
│  Queue 中的每个 item:                                   │
│    (domain, example_id)                                 │
│    例: ("chrome", "test_google_search")                 │
└───────────────────────────┬─────────────────────────────┘
                            ↓
                    task_queue
```

---

### 2.3 任务队列 → 多进程分发

**位置:** `run_multienv_evocua.py:404-413`

**数据流转:**

```
task_queue + args
    ↓
┌─────────────────────────────────────────────────────────┐
│  多进程池创建                                            │
│  位置: run_multienv_evocua.py:404-413                   │
├─────────────────────────────────────────────────────────┤
│  输入: task_queue, args, num_envs                        │
│  输出: processes (List[Process])                        │
│                                                         │
│  数据分发:                                              │
│  - 创建 num_envs 个进程                                 │
│  - 每个进程执行 run_env_tasks 函数                      │
│  - 所有进程共享 task_queue                              │
│  - 进程间共享 shared_scores (Manager.list)              │
└───────────────────────────┬─────────────────────────────┘
                            ↓
              ┌─────────────┴─────────────┐
              ↓           ↓           ↓
         Process-1   Process-2   Process-N
         (worker)    (worker)     (worker)
```

---

### 2.4 单个进程：任务执行循环

**位置:** `run_multienv_evocua.py:232-350`

**数据流转:**

```
单个 Worker 进程
    ↓
┌─────────────────────────────────────────────────────────┐
│  从队列获取任务                                          │
│  位置: run_multienv_evocua.py:265-268                   │
├─────────────────────────────────────────────────────────┤
│  输入: task_queue                                       │
│  输出: (domain, example_id)                             │
│                                                         │
│  示例:                                                  │
│  ("chrome", "test_google_search")                       │
└───────────────────────────┬─────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────┐
│  加载任务配置文件                                        │
│  位置: run_multienv_evocua.py:271-275                   │
├─────────────────────────────────────────────────────────┤
│  输入: domain, example_id                               │
│  输出: example (dict)                                   │
│                                                         │
│  文件路径模式:                                          │
│  evaluation_examples/examples/{domain}/{example_id}.json│
│                                                         │
│  数据格式:                                              │
│  {                                                      │
│    "id": "task_id",                                    │
│    "instruction": "Open Chrome and search...",          │
│    "config": {...},  // 环境配置                        │
│    "eval": {...}     // 评估标准                        │
│  }                                                      │
└───────────────────────────┬─────────────────────────────┘
                            ↓
                        example 对象
```

---

### 2.5 任务配置 → 环境初始化

**位置:** `run_multienv_evocua.py:246-260`

**数据流转:**

```
args (配置参数)
    ↓
┌─────────────────────────────────────────────────────────┐
│  DesktopEnv 初始化                                      │
│  位置: run_multienv_evocua.py:246-258                   │
├─────────────────────────────────────────────────────────┤
│  输入: args 配置参数                                     │
│  输出: env (DesktopEnv 实例)                            │
│                                                         │
│  关键输入数据:                                          │
│  - provider_name: "aws"                                │
│  - region: "us-east-1"                                 │
│  - screen_size: (1920, 1080)                           │
│  - headless: True                                      │
│  - require_a11y_tree: False                            │
│                                                         │
│  内部流程:                                              │
│  1. 创建 Provider (AWS/Azure/Docker等)                  │
│  2. 启动虚拟机实例                                      │
│  3. 建立 SSH 连接                                       │
│  4. 初始化 Controller (PythonController)                │
│  5. 初始化 Evaluator                                    │
└───────────────────────────┬─────────────────────────────┘
                            ↓
                        env 对象
```

---

### 2.6 环境和配置 → Agent 初始化

**位置:** `run_multienv_evocua.py:290-304`

**数据流转:**

```
args (配置参数)
    ↓
┌─────────────────────────────────────────────────────────┐
│  EvoCUAAgent 初始化                                     │
│  位置: run_multienv_evocua.py:290-304                   │
├─────────────────────────────────────────────────────────┤
│  输入: args 配置参数                                     │
│  输出: agent (EvoCUAAgent 实例)                         │
│                                                         │
│  关键输入数据:                                          │
│  - model: "EvoCUA-S2"                                  │
│  - max_tokens: 32768                                   │
│  - prompt_style: "S2"                                  │
│  - max_history_turns: 4                                │
│  - coordinate_type: "relative"                         │
│  - resize_factor: 32                                   │
│                                                         │
│  Agent 内部状态初始化:                                  │
│  - thoughts = []                                       │
│  - actions = []                                        │
│  - observations = []                                   │
│  - responses = []                                      │
│  - screenshots = []                                    │
│  - cots = []                                           │
└───────────────────────────┬─────────────────────────────┘
                            ↓
                        agent 对象
```

---

### 2.7 核心循环：单任务执行

**位置:** `lib_run_single.py:18-116`

**完整数据流:**

```
[输入数据]
    ├── agent (EvoCUAAgent)
    ├── env (DesktopEnv)
    ├── example (任务配置)
    ├── max_steps (最大步数)
    └── instruction (任务指令)
    ↓
┌─────────────────────────────────────────────────────────┐
│  Step 1: 环境重置                                       │
│  位置: lib_run_single.py:25                             │
├─────────────────────────────────────────────────────────┤
│  输入: env, example                                     │
│  输出: env (重置后状态)                                 │
│                                                         │
│  调用: env.reset(task_config=example)                   │
│                                                         │
│  内部数据流:                                            │
│  example["config"] → Provider → 虚拟机环境设置          │
│  example["instruction"] → env.instruction               │
└───────────────────────────┬─────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────┐
│  Step 2: Agent 重置                                     │
│  位置: lib_run_single.py:29-35                          │
├─────────────────────────────────────────────────────────┤
│  输入: agent                                            │
│  输出: agent (重置后状态)                               │
│                                                         │
│  调用: agent.reset()                                    │
│                                                         │
│  内部数据流:                                            │
│  agent.thoughts = []                                   │
│  agent.actions = []                                    │
│  agent.observations = []                               │
│  agent.responses = []                                  │
│  agent.screenshots = []                                │
└───────────────────────────┬─────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────┐
│  Step 3: 获取初始观察                                   │
│  位置: lib_run_single.py:38                             │
├─────────────────────────────────────────────────────────┤
│  输入: env                                               │
│  输出: obs (dict)                                       │
│                                                         │
│  调用: obs = env._get_obs()                             │
│                                                         │
│  数据格式:                                              │
│  {                                                      │
│    "screenshot": bytes,  # PNG 图片字节数据             │
│    "a11y_tree": dict,   # 可访问性树 (可选)             │
│    "window_info": dict  # 窗口信息 (可选)               │
│  }                                                      │
└───────────────────────────┬─────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────┐
│  Step 4: 开始录制                                       │
│  位置: lib_run_single.py:42                             │
├─────────────────────────────────────────────────────────┤
│  调用: env.controller.start_recording()                 │
│                                                         │
│  作用: 开始屏幕录制，保存为 recording.mp4               │
└───────────────────────────┬─────────────────────────────┘
                            ↓
                    ┌───────┴───────┐
                    ↓               ↓
            [执行循环开始]      [迭代直到完成]
                    ↓
```

---

### 2.8 执行循环：Agent 决策

**位置:** `lib_run_single.py:43-103`

**循环内的数据流:**

```
[循环输入]
    ├── instruction (任务指令)
    ├── obs (当前观察)
    ├── agent (智能体)
    └── env (环境)
    ↓
┌─────────────────────────────────────────────────────────┐
│  Step 4.1: Agent 预测                                   │
│  位置: lib_run_single.py:46                             │
├─────────────────────────────────────────────────────────┤
│  输入: instruction, obs                                  │
│  输出: response, actions, info_dict                     │
│                                                         │
│  调用: predict_res = agent.predict(instruction, obs)    │
│                                                         │
│  内部数据流 → 见 2.9 节详细说明                          │
└───────────────────────────┬─────────────────────────────┘
                            ↓
                      response + actions
```

---

### 2.9 Agent.predict() 内部数据流 (S2 模式)

**位置:** `evocua_agent.py:97-195`

**详细数据流:**

```
[输入]
    ├── instruction (str): "Open Chrome and search for..."
    └── obs (dict): {"screenshot": bytes, ...}
    ↓
┌─────────────────────────────────────────────────────────┐
│  Step 1: 提取并处理截图                                 │
│  位置: evocua_agent.py:105-129                          │
├─────────────────────────────────────────────────────────┤
│  输入: obs["screenshot"] (bytes)                         │
│  输出: processed_b64 (str), p_width, p_height           │
│                                                         │
│  处理流程 (S2 模式):                                    │
│  1. 原始截图 (bytes)                                    │
│  2. PIL Image.open() → Image 对象                      │
│  3. process_image() → resize 到 32x32 网格              │
│  4. encode_image() → Base64 编码                        │
│  5. 保存到 agent.screenshots 列表                       │
│                                                         │
│  数据变换:                                              │
│  原始 (1920x1080 PNG) → 处理后 (1000x1000 PNG)         │
│                   ↓ Base64 编码                          │
│                   processed_b64 字符串                   │
└───────────────────────────┬─────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────┐
│  Step 2: 构建 Prompt                                    │
│  位置: evocua_agent.py:132-275                          │
├─────────────────────────────────────────────────────────┤
│  输入: instruction, processed_b64, history              │
│  输出: messages (List[Dict])                            │
│                                                         │
│  数据结构:                                              │
│  messages = [                                           │
│    {                                                    │
│      "role": "system",                                  │
│      "content": [                                       │
│        {"type": "text", "text": S2_SYSTEM_PROMPT}      │
│      ]                                                  │
│    },                                                   │
│    {                                                    │
│      "role": "user",                                    │
│      "content": [                                       │
│        {"type": "image_url",                            │
│         "image_url": {"url": "data:image/png;base64,..."}},│
│        {"type": "text",                                │
│         "text": "Instruction: ...\nPrevious actions: ..."}│
│      ]                                                  │
│    },                                                   │
│    ... (历史对话)                                        │
│  ]                                                      │
│                                                         │
│  历史窗口: max_history_turns (4 轮)                     │
│    - 包含过去的 4 张截图                                │
│    - 包含过去的 4 个响应                                │
└───────────────────────────┬─────────────────────────────┘
                            ↓
                        messages
```

```
┌─────────────────────────────────────────────────────────┐
│  Step 3: 调用 LLM API                                   │
│  位置: evocua_agent.py:160-167                          │
├─────────────────────────────────────────────────────────┤
│  输入: messages                                         │
│  输出: response (str)                                   │
│                                                         │
│  调用: response = self.call_llm({                       │
│    "model": "EvoCUA-S2",                               │
│    "messages": messages,                                │
│    "max_tokens": 32768,                                │
│    "temperature": 0.01,                                │
│    "top_p": 0.9                                        │
│  })                                                     │
│                                                         │
│  内部流程 (call_llm):                                   │
│  位置: evocua_agent.py:627-653                          │
│  1. 创建 OpenAI 客户端                                  │
│     client = openai.OpenAI(                             │
│       base_url=os.environ["OPENAI_BASE_URL"],           │
│       api_key=os.environ["OPENAI_API_KEY"]              │
│     )                                                   │
│  2. 调用 vLLM 服务                                       │
│     resp = client.chat.completions.create(**params)     │
│  3. 提取响应内容                                        │
│     response = resp.choices[0].message.content          │
│                                                         │
│  LLM 响应格式 (S2 模式):                                │
│  Action: Search for information about cats              │
│  ```                                                     │
│  {                                                      │
│    "name": "computer_use",                              │
│    "arguments": {                                       │
│      "action": "type",                                  │
│      "text": "cats"                                     │
│    }                                                    │
│  }                                                      │
│  ```                                                     │
└───────────────────────────┬─────────────────────────────┘
                            ↓
                        response (str)
```

```
┌─────────────────────────────────────────────────────────┐
│  Step 4: 解析响应                                       │
│  位置: evocua_agent.py:179-195                          │
├─────────────────────────────────────────────────────────┤
│  输入: response, p_width, p_height,                      │
│       original_width, original_height                   │
│  输出: low_level_instruction, pyautogui_code             │
│                                                         │
│  调用: self._parse_response_s2(...)                     │
│  位置: evocua_agent.py:278-521                          │
│                                                         │
│  解析流程:                                              │
│  1. 提取 Action 描述                                    │
│     low_level_instruction = "Search for information..." │
│                                                         │
│  2. 解析 JSON 工具调用                                   │
│     tool_call = {                                       │
│       "name": "computer_use",                           │
│       "arguments": {                                   │
│         "action": "type",                               │
│         "text": "cats"                                 │
│       }                                                 │
│     }                                                   │
│                                                         │
│  3. 转换为 PyAutoGUI 代码                               │
│     坐标调整:                                           │
│     - relative (0-999) → 屏幕绝对坐标                   │
│       x_abs = int((x / 999) * original_width)           │
│       y_abs = int((y / 999) * original_height)          │
│     - absolute (处理后像素) → 屏幕绝对坐标              │
│       x_abs = int((x / p_width) * original_width)       │
│                                                         │
│  4. 生成 PyAutoGUI 命令列表                              │
│     pyautogui_code = [                                  │
│       "pyautogui.press('c')",                          │
│       "pyautogui.press('a')",                          │
│       "pyautogui.press('t')",                          │
│       "pyautogui.press('s')",                          │
│     ]                                                   │
│                                                         │
│  5. 保存到 agent 状态                                    │
│     agent.actions.append(low_level_instruction)         │
│     agent.responses.append(response)                    │
│                                                         │
│  输出格式:                                              │
│  - low_level_instruction: str (自然语言描述)            │
│  - pyautogui_code: List[str] (PyAutoGUI 命令列表)       │
└───────────────────────────┬─────────────────────────────┘
                            ↓
              low_level_instruction + pyautogui_code
```

---

### 2.10 执行循环：环境执行动作

**位置:** `lib_run_single.py:65-101`

**数据流:**

```
[输入]
    ├── actions (List[str]): pyautogui 命令
    └── env (DesktopEnv)
    ↓
┌─────────────────────────────────────────────────────────┐
│  Step 4.2: 遍历执行每个动作                             │
│  位置: lib_run_single.py:65                             │
├─────────────────────────────────────────────────────────┤
│  for action in actions:                                 │
│    └── 执行单个动作                                      │
└───────────────────────────┬─────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────┐
│  Step 4.3: 环境执行单个动作                             │
│  位置: lib_run_single.py:70                             │
├─────────────────────────────────────────────────────────┤
│  输入: action (str), sleep_after_execution (float)      │
│  输出: obs, reward, done, info                          │
│                                                         │
│  调用: obs, reward, done, info = env.step(action, ...)  │
│                                                         │
│  内部数据流 (DesktopEnv.step):                          │
│  位置: desktop_env.py                                   │
│                                                         │
│  1. 动作类型解析                                        │
│     例: "pyautogui.click(100, 200)"                    │
│     → 提取: action_type="click", x=100, y=200          │
│                                                         │
│  2. 转换为可执行命令                                    │
│     → python_code = f"import pyautogui; ..."           │
│                                                         │
│  3. 通过 SSH 发送到虚拟机                                │
│     controller.execute_python(python_code)              │
│     ↓                                                   │
│     VM 执行: 鼠标点击坐标 (100, 200)                    │
│                                                         │
│  4. 等待执行完成                                        │
│     time.sleep(sleep_after_execution)  # 默认 5秒       │
│                                                         │
│  5. 获取新观察                                          │
│     obs = env._get_obs()                                │
│     - 截取新的屏幕截图                                  │
│     - 获取可访问性树 (可选)                             │
│     - 获取窗口信息 (可选)                               │
│                                                         │
│  输出数据:                                              │
│  - obs: {"screenshot": bytes, ...}                     │
│  - reward: float (通常为 0.0，任务完成时更新)           │
│  - done: bool (任务是否完成)                            │
│  - info: dict (额外信息)                                │
└───────────────────────────┬─────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────┐
│  Step 4.4: 记录轨迹                                     │
│  位置: lib_run_single.py:81-97                          │
├─────────────────────────────────────────────────────────┤
│  输入: step_idx, action, response, obs, reward, done    │
│  输出: traj.jsonl (追加写入)                            │
│                                                         │
│  数据格式:                                              │
│  {                                                      │
│    "step_num": 1,                                      │
│    "action_timestamp": "20260129@123456789",            │
│    "action": "pyautogui.click(100, 200)",              │
│    "response": "Action: Click search bar...",          │
│    "reward": 0.0,                                       │
│    "done": false,                                      │
│    "info": {...},                                       │
│    "screenshot_file": "step_1_20260129@123456789.png"  │
│  }                                                      │
│                                                         │
│  同时保存截图文件                                        │
│  → example_result_dir/step_1_<timestamp>.png           │
└───────────────────────────┬─────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────┐
│  Step 4.5: 判断退出条件                                 │
│  位置: lib_run_single.py:99-103                         │
├─────────────────────────────────────────────────────────┤
│  判断逻辑:                                              │
│  if done:                                               │
│    break (跳出循环)                                     │
│  if step_idx >= max_steps:                              │
│    break (达到最大步数)                                 │
│                                                         │
│  否则:                                                  │
│    step_idx += 1                                       │
│    返回到 Step 4.1 (继续预测)                           │
└───────────────────────────┬─────────────────────────────┘
                            ↓
                    [循环结束]
```

---

### 2.11 任务评估

**位置:** `lib_run_single.py:105-116`

**数据流:**

```
[循环结束]
    ↓
┌─────────────────────────────────────────────────────────┐
│  Step 5: 等待环境稳定                                   │
│  位置: lib_run_single.py:105                             │
├─────────────────────────────────────────────────────────┤
│  time.sleep(20)  # 等待 20 秒                           │
└───────────────────────────┬─────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────┐
│  Step 6: 任务评估                                       │
│  位置: lib_run_single.py:106                             │
├─────────────────────────────────────────────────────────┤
│  输入: env                                               │
│  输出: result (float)                                   │
│                                                         │
│  调用: result = env.evaluate()                          │
│                                                         │
│  内部数据流 (DesktopEnv.evaluate):                      │
│  位置: desktop_env.py                                   │
│                                                         │
│  1. 加载评估标准                                        │
│     eval_config = example["eval"]                       │
│     例: {                                               │
│       "eval_type": "html",                             │
│       "expect": {                                      │
│         "search_query": "cats"                         │
│       }                                                │
│     }                                                   │
│                                                         │
│  2. 选择 Getter (数据获取器)                             │
│     getter = getters.get(eval_type)                     │
│     例: ChromeGetter.get_search_history()               │
│                                                         │
│  3. 选择 Metric (评估指标)                               │
│     metric = metrics.get(eval_type)                     │
│     例: string_match                                    │
│                                                         │
│  4. 执行获取和评估                                      │
│     actual_data = getter(env, eval_config)              │
│         ↓ 通过 SSH 连接虚拟机                           │
│         ↓ 读取浏览器历史/文件内容等                     │
│         ↓ 返回实际数据                                  │
│                                                         │
│     result = metric(actual_data, expected_data)         │
│         ↓ 比较实际和期望数据                            │
│         ↓ 返回 0.0 或 1.0                               │
│                                                         │
│  输出:                                                  │
│  result = 1.0 (成功) 或 0.0 (失败)                      │
└───────────────────────────┬─────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────┐
│  Step 7: 记录结果                                       │
│  位置: lib_run_single.py:108-116                        │
├─────────────────────────────────────────────────────────┤
│  1. 保存到共享列表                                      │
│     scores.append(result)                               │
│     ↓ 所有进程共享                                      │
│     ↓ 用于计算平均成功率                                │
│                                                         │
│  2. 保存到文件                                          │
│     with open("result.txt", "w") as f:                 │
│       f.write(f"{result}\n")                            │
│                                                         │
│  3. 记录任务完成日志                                    │
│     log_task_completion(example, result, ...)           │
│                                                         │
│  4. 结束录制                                            │
│     env.controller.end_recording("recording.mp4")       │
└───────────────────────────┬─────────────────────────────┘
                            ↓
                    [单个任务完成]
```

---

### 2.12 多进程汇总与最终输出

**位置:** `run_multienv_evocua.py:454-456`

**数据流:**

```
[所有进程完成任务]
    ↓
┌─────────────────────────────────────────────────────────┐
│  收集共享结果列表                                        │
│  位置: run_multienv_evocua.py:454                        │
├─────────────────────────────────────────────────────────┤
│  输入: shared_scores (Manager.list)                     │
│  输出: scores (List[float])                             │
│                                                         │
│  scores = [1.0, 0.0, 1.0, 1.0, 0.0, ...]                │
│  (每个任务的成功/失败分数)                               │
└───────────────────────────┬─────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────┐
│  计算平均成功率                                          │
│  位置: run_multienv_evocua.py:455                        │
├─────────────────────────────────────────────────────────┤
│  输入: scores                                            │
│  输出: average_score (float)                            │
│                                                         │
│  average_score = sum(scores) / len(scores)              │
│  例: 0.75 (75% 成功率)                                  │
│                                                         │
│  输出到控制台:                                          │
│  logger.info(f"Average score: {average_score}")         │
└───────────────────────────┬─────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────┐
│  返回给用户 (最终输出)                                   │
├─────────────────────────────────────────────────────────┤
│  输出渠道:                                              │
│                                                         │
│  1. 控制台日志                                          │
│     - 每个任务的执行状态                                │
│     - 最终平均成功率                                    │
│                                                         │
│  2. 文件系统                                            │
│     ├── args.json (配置参数)                            │
│     ├── {result_dir}/                                   │
│     │   ├── {domain}/{example_id}/                      │
│     │   │   ├── result.txt (任务分数)                   │
│     │   │   ├── traj.jsonl (完整轨迹)                   │
│     │   │   ├── recording.mp4 (录屏)                    │
│     │   │   ├── step_*.png (每步截图)                   │
│     │   │   └── runtime.log (运行日志)                  │
│     │                                                   │
│  3. 日志文件                                            │
│     ├── logs/normal-*.log (INFO 级别)                  │
│     └── logs/debug-*.log (DEBUG 级别)                   │
└─────────────────────────────────────────────────────────┘
                            ↓
                    [程序结束]
```

---

## 3. 数据流时序图

### 3.1 单任务完整时序

```
用户输入命令
    ↓
[主进程]
    加载配置 → 读取任务 → 创建队列 → 启动进程
    ↓
[Worker 进程]
    ↓
    获取任务 (domain, example_id)
    ↓
    加载任务配置 example.json
    ↓
    初始化 DesktopEnv
        ↓ (SSH 连接)
        AWS/Azure 虚拟机
    ↓
    初始化 EvoCUAAgent
    ↓
    环境重置 env.reset(example)
        ↓ (SSH 命令)
        VM: 重置到初始状态
    ↓
    Agent 重置 agent.reset()
    ↓
    获取初始观察 obs = env._get_obs()
        ↓ (SSH 命令)
        VM: 截取屏幕
        ↓ (返回字节流)
        obs["screenshot"] = bytes
    ↓
    开始录制
    ↓
    ┌─────────────────────────────────────┐
    │  循环 (step_idx = 0 to max_steps)   │
    │                                     │
    │  1. Agent 预测                      │
    │     response, actions =             │
    │       agent.predict(instruction, obs)│
    │     ↓                               │
    │     内部:                           │
    │       - 处理截图 (resize + encode)  │
    │       - 构建 prompt (历史+截图+指令) │
    │       - 调用 LLM API                │
    │         ↓ (HTTP 请求)               │
    │         vLLM 服务 (EvoCUA 模型)     │
    │         ↓ (返回响应)                │
    │       - 解析响应 (JSON → pyautogui) │
    │     ↓                               │
    │     response + actions              │
    │                                     │
    │  2. 执行动作                        │
    │     for action in actions:          │
    │       obs, reward, done, info =     │
    │         env.step(action)            │
    │       ↓                             │
    │       内部:                         │
    │         - 解析 pyautogui 命令        │
    │         - 转换为 Python 代码        │
    │         - 通过 SSH 发送到 VM        │
    │           ↓                         │
    │           VM: 执行动作               │
    │           (点击/输入/滚动等)         │
    │         - 等待 5 秒                  │
    │         - 获取新观察                │
    │           ↓ (SSH 命令)              │
    │           VM: 截取新屏幕             │
    │           ↓ (返回字节流)            │
    │           obs["screenshot"] = bytes │
    │     ↓                               │
    │     obs + reward + done + info      │
    │                                     │
    │  3. 记录轨迹                        │
    │     保存到 traj.jsonl               │
    │     保存截图 step_*.png             │
    │                                     │
    │  4. 判断退出                        │
    │     if done or step_idx >= max_steps:│
    │       break                         │
    │     else:                           │
    │       step_idx += 1                 │
    │       回到步骤 1                     │
    │                                     │
    └─────────────────────────────────────┘
    ↓
    任务评估 env.evaluate()
        ↓ (SSH 命令)
        VM: 读取应用状态
        ↓ (返回数据)
        比较期望结果
        ↓
    result = 1.0 (成功) 或 0.0 (失败)
    ↓
    保存结果 result.txt
    ↓
    结束录制 recording.mp4
    ↓
    更新共享分数列表 scores.append(result)
    ↓
    获取下一个任务 或 结束
```

---

## 4. 关键数据结构

### 4.1 任务配置 (example)

```json
{
  "id": "chrome_google_search",
  "instruction": "Open Chrome browser and search for information about cats",
  "config": {
    "locale": "en-US",
    "disable_spellcheck": true
  },
  "eval": {
    "type": "html",
    "expect": {
      "search_query": "cats"
    }
  },
  "source": "osworld"
}
```

### 4.2 观察 (obs)

```python
{
  "screenshot": b'\x89PNG\r\n\x1a\n...'  # PNG 字节数据
  # "a11y_tree": {...}  # 可选
  # "window_info": {...}  # 可选
}
```

### 4.3 LLM 响应 (response - S2 模式)

```text
Action: Type "cats" in the search bar

```json
{
  "name": "computer_use",
  "arguments": {
    "action": "type",
    "text": "cats"
  }
}
```
```

### 4.4 PyAutoGUI 命令 (actions)

```python
[
  "pyautogui.press('c')",
  "pyautogui.press('a')",
  "pyautogui.press('t')",
  "pyautogui.press('s')"
]
```

### 4.5 轨迹记录 (traj.jsonl)

```json
{
  "step_num": 1,
  "action_timestamp": "20260129@123456789",
  "action": "pyautogui.click(500, 100)",
  "response": "Action: Click on the search bar...",
  "reward": 0.0,
  "done": false,
  "info": {"screenshot_path": "step_1_..."},
  "screenshot_file": "step_1_20260129@123456789.png"
}
```

---

## 5. 数据传递总结

### 输入数据流

```
用户 (命令行) → argparse → args (Namespace)
                            ↓
用户 (.env) → os.environ → 环境变量
                            ↓
用户 (JSON) → test_all_meta → 任务列表
                            ↓
                            task_queue
```

### 内部数据流

```
task_queue → (domain, example_id)
    ↓
example.json → example (dict)
    ↓
example + args → env (DesktopEnv)
    ↓
example + args → agent (EvoCUAAgent)
    ↓
[循环]
  instruction + obs → agent.predict()
    ↓
    screenshot (bytes) → processed_b64 (str)
    ↓
    messages (list) → LLM API
    ↓
    response (str) → actions (list)
    ↓
    actions → env.step()
      ↓
      SSH → VM → 执行动作
      ↓
      obs (bytes)
    ↓
    traj.jsonl + screenshot
```

### 输出数据流

```
env.evaluate() → result (float: 0.0/1.0)
    ↓
result.txt + scores (shared list)
    ↓
average_score = sum(scores) / len(scores)
    ↓
logger.info() → 控制台
    ↓
文件系统 → result_dir/...
```

---

**文档版本:** 2.0
**最后更新:** 2026-01-29
**维护者:** EvoCUA Team

**说明:** 本文档专注于业务数据在系统内部的流转过程，从用户输入到最终返回结果的完整路径。
